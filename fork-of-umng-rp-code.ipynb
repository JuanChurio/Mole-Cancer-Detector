{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**DETECCIÓN DE LUNARES CANCERIGENOS**","metadata":{}},{"cell_type":"markdown","source":"*Presentado por: Juan Felipe Churio, Julian Motivar y Paula Ocampo*","metadata":{}},{"cell_type":"markdown","source":"Primero se tendrá que importar todas las librerias necesarias","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nfrom skimage import feature\nfrom sklearn import svm \nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom skimage.feature import hog\nfrom joblib import dump, load\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:39:42.895843Z","iopub.execute_input":"2023-05-31T14:39:42.896225Z","iopub.status.idle":"2023-05-31T14:39:44.097846Z","shell.execute_reply.started":"2023-05-31T14:39:42.896199Z","shell.execute_reply":"2023-05-31T14:39:44.096329Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"La clase \"Image\" es necesaria para tener un facil seguimiento del label y la imagen\n","metadata":{}},{"cell_type":"code","source":"class Image:\n    def __init__(self, image, malicious):\n        self.image = image\n        self.malicious = malicious\n\nfolder_path = \"/kaggle/input/umng-rp/images/train\"\nfolder_path_test = \"/kaggle/input/umng-rp/images/test\"","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:39:46.910336Z","iopub.execute_input":"2023-05-31T14:39:46.910769Z","iopub.status.idle":"2023-05-31T14:39:46.917341Z","shell.execute_reply.started":"2023-05-31T14:39:46.910738Z","shell.execute_reply":"2023-05-31T14:39:46.915773Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"En la siguiente se cargan todas las imagenes deseadas con la clase \"Image\" ","metadata":{}},{"cell_type":"code","source":"def processing():\n    images = []\n    benign_path = os.path.join(folder_path, \"benign\")\n    malicious_path = os.path.join(folder_path, \"malignant\")\n\n    for filename in os.listdir(benign_path):\n        file_path = os.path.join(benign_path, filename)\n        aux_image = cv2.imread(file_path, 0)\n        new_image = Image(aux_image, 0)\n        images.append(new_image)\n\n    for filename in os.listdir(malicious_path):\n        file_path = os.path.join(malicious_path, filename)\n        aux_image = cv2.imread(file_path, 0)\n        new_image = Image(aux_image, 1)\n        images.append(new_image)\n\n    return images\nimages=processing()","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:39:49.014707Z","iopub.execute_input":"2023-05-31T14:39:49.015053Z","iopub.status.idle":"2023-05-31T14:40:17.561513Z","shell.execute_reply.started":"2023-05-31T14:39:49.015029Z","shell.execute_reply":"2023-05-31T14:40:17.560490Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"La siguiente funcion recolecta un vector de caracteristicas por cada Imagen, formando una matriz de caracteristicas junto con el arreglo de labels","metadata":{}},{"cell_type":"code","source":"def collecting_features(hog, images,cell_size,block_size,num_bins):\n    hog_features = []\n    lbp_hist = []\n    labels = []\n    features = []\n   \n    for image in images:\n        feature_vector = feature.hog(image.image, orientations=num_bins, pixels_per_cell=cell_size, cells_per_block=block_size, visualize=False, block_norm='L2-Hys')\n        \n        lbp = feature.local_binary_pattern(image.image, 8, 1, method='uniform')\n        hist, _ = np.histogram(lbp.ravel(), bins=int(lbp.max() + 1))\n        concatenated_features = np.concatenate((feature_vector.ravel(), hist))\n        features.append(concatenated_features)\n        labels.append(image.malicious)\n\n    features = np.array(features)\n    labels = np.array(labels)\n    \n    return features,labels","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:40:33.024607Z","iopub.execute_input":"2023-05-31T14:40:33.024968Z","iopub.status.idle":"2023-05-31T14:40:33.033654Z","shell.execute_reply.started":"2023-05-31T14:40:33.024944Z","shell.execute_reply":"2023-05-31T14:40:33.031904Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"En esta función se hace la validación cruzada, primero se divide el conjunto de imágenes en cuatro partes utilizando la función np.array_split(images, 4). Luego, se le asigna cada una de las partes a las variables parte_1, parte_2, parte_3 y parte_4.\n\nLuego en el condicional se determina qué parte de las imágenes se utiliza como conjunto de prueba y cuáles se utilizan como conjunto de entrenamiento. Dependiendo del valor de test_number que se asigne a la función, se concatenan las partes correspondientes para formar el conjunto de entrenamiento llamado nuevo_arreglo y se llaman a la función collecting_features para asi  poder extraer las características HOG  y LBP y las etiquetas tanto para el conjunto de entrenamiento como para el conjunto de prueba. \n\nLa función collecting_features se llama dos veces en cada condicional, una para el conjunto de entrenamiento y otra para el conjunto de prueba, utilizando diferentes parámetros de configuración para determinar cuales son los mas aptos para el testeo.","metadata":{}},{"cell_type":"code","source":"labals_predict=[]\nfor image  in images:\n        labels_predict.append(image.malicious)\n        \nlabels_1 = np.array(labels_predict[:660])\nlabels_2 = np.array(labels_predict[660:1319])\nlabels_3 = np.array(labels_predict[1319:1978])\nlabels_4 = np.array(labels_predict[1978:])","metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:56:08.575565Z","iopub.execute_input":"2023-05-31T15:56:08.575938Z","iopub.status.idle":"2023-05-31T15:56:08.583456Z","shell.execute_reply.started":"2023-05-31T15:56:08.575911Z","shell.execute_reply":"2023-05-31T15:56:08.582437Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def Across_Validation(test_number,images):\n    \n    Split_Array= np.array_split(images.copy(),4)\n    parte_1 = Split_Array[0]\n    parte_2 = Split_Array[1]\n    parte_3 = Split_Array[2]\n    parte_4 = Split_Array[3]\n    print(len(parte_1))\n    print(len(parte_2))\n    print(len(parte_3))\n    print(len(parte_4))\n    if test_number == 1:\n        nuevo_arreglo = np.concatenate([parte_2, parte_3, parte_4])\n        features_Across, labels_Across = collecting_features(hog, nuevo_arreglo,(8,8),(2,2),9)\n        features_test_Across, labels_test_Across = collecting_features(hog, parte_1,(8,8),(2,2),9)\n        \n            \n    if test_number == 2:\n        nuevo_arreglo = np.concatenate([parte_1, parte_3, parte_4])\n        features_Across, labels_Across = collecting_features(hog, nuevo_arreglo,(6, 16), (3, 3), 12)\n        features_test_Across, labels_test_Across = collecting_features(hog, parte_2,(6, 16), (3, 3), 12)\n        \n    if test_number == 3:\n        nuevo_arreglo = np.concatenate([parte_1, parte_2, parte_4])\n        features_Across, labels_Across = collecting_features(hog, nuevo_arreglo,(8,8),(2,2),9)\n        features_test_Across, labels_test_Across = collecting_features(hog, parte_3,(8,8),(2,2),9)\n        \n    if test_number == 4:\n        nuevo_arreglo = np.concatenate([parte_1, parte_2, parte_3])\n        features_Across, labels_Across = collecting_features(hog, nuevo_arreglo,(8,8),(2,2),9)\n        features_test_Across, labels_test_Across = collecting_features(hog, parte_4,(8,8),(2,2),9)\n        \n    print(len(labels_predict))\n    return features_Across, labels_Across, features_test_Across\n\n\nfeatures_Across = [0,0,0,0]\nlabels_Across= [0,0,0,0]\nfeature_test= [0,0,0,0]\npredict=[0,0,0,0]\nlabels_predict = [0,0,0,0]\nfeatures_Across[0], labels_Across[0],feature_test[0] = Across_Validation(1,images)\nfeatures_Across[1], labels_Across[1],feature_test[1] = Across_Validation(2,images)\nfeatures_Across[2], labels_Across[2],feature_test[2] = Across_Validation(3,images)\nfeatures_Across[3], labels_Across[3],feature_test[3] = Across_Validation(4,images)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:50:06.721181Z","iopub.execute_input":"2023-05-31T15:50:06.721641Z","iopub.status.idle":"2023-05-31T15:54:25.217008Z","shell.execute_reply.started":"2023-05-31T15:50:06.721611Z","shell.execute_reply":"2023-05-31T15:54:25.216020Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"660\n659\n659\n659\n4\n660\n659\n659\n659\n4\n660\n659\n659\n659\n4\n660\n659\n659\n659\n4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"A continuación entrenamos y evalúamos el clasificador SVM con un kernel  de tipo lineal usando las características y etiquetas que obtuvimos en la validación cruzada.\n\nInicializamos las listas que se usan para almacenar los valores de las características, etiquetas, clasificadores SVM, etiquetas para cada prueba y los colores para las graficas de las curvas ROC.\n\nUna vez el clasificador fue entrenado, relaizamos una predicción en el conjunto de prueba utilizando svm_classifier[i].predict(feature_test[i]) y liego lo almacenamos en la lista predict[i] para imprimir el resultado de la predicción.\n\nAsi mismo se calcula el area bajo la curva AUC empleando las funciones roc_curve y roc_auc_score de la libreria scikit-learn, para poder graficar las curvas ROC y mostrar su respectiva AUC. \n\nFinalmente, se guardan los clasificadores previamente entrenados para cada caso de la validación.","metadata":{}},{"cell_type":"code","source":"features_np=[0,0,0,0]\nlabels_np=[0,0,0,0]\nsvm_classifier=[0,0,0,0]\nABCD=[\"A\",\"B\",\"C\",\"D\"]\ncolors=['#2E5063','#347E92','#2E5063','#347E92']\naccurracy = [0,0,0,0]\npredict = [0,0,0,0]\nfor i in range(4):\n    features_np[i] = np.array(features_Across[i], dtype=np.float32)\n    labels_np[i] = np.array(labels_Across[i])\n    svm_classifier[i] = svm.SVC(kernel=\"linear\")\n    svm_classifier[i].fit(features_np[i], labels_np[i])\n\n    predict[i] = svm_classifier[i].predict(feature_test[i])\n    \n\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-31T16:11:39.534633Z","iopub.execute_input":"2023-05-31T16:11:39.535033Z","iopub.status.idle":"2023-05-31T16:30:44.773875Z","shell.execute_reply.started":"2023-05-31T16:11:39.535003Z","shell.execute_reply":"2023-05-31T16:30:44.773039Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"\nprint(len(predict[3]),len(labels_4))\nlabels_2 = labels_2[:len(predict[1])]\nlabels_4 = labels_4[:len(predict[3])]\n\nacurracy1 = accuracy_score(labels_1, predict[0])\nacurracy2 = accuracy_score(labels_2, predict[1])\nacurracy3 = accuracy_score(labels_3, predict[2])\nacurracy4 = accuracy_score(labels_4, predict[3])\n\n\n\nprint(acurracy1)\nprint(acurracy2)\nprint(acurracy3)\nprint(acurracy4)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-31T16:38:29.910854Z","iopub.execute_input":"2023-05-31T16:38:29.911312Z","iopub.status.idle":"2023-05-31T16:38:29.924394Z","shell.execute_reply.started":"2023-05-31T16:38:29.911272Z","shell.execute_reply":"2023-05-31T16:38:29.922992Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"659 659\n0.7303030303030303\n0.6843702579666161\n0.6949924127465857\n0.5569044006069803\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Resultados:**\n\nSe puede ver que la implementación de la validación cruzada permitió evaluar la estabilidad y la calidad del clasificador al entrenarlo y evaluarlo en diferentes subconjuntos de datos y con diferentes valores de los hiperparámetros. En este caso el rendimiento del modelo es más consistente en todas las iteraciones del **svm_rpA** con un AUC de 0.9484619668830194 indica que el clasificador tiene un rendimiento muy bueno, ya que se acerca a 1.0. Esto significa que el clasificador tiene una alta capacidad para distinguir entre las clases positiva y negativa, por ende esto indica que este modelo es el más robusto. Asi mismo se puede observar que el modelo mas debil fue el **svm_rpB** con un AUC de 0.7988633555720286 que aunque también indica que el calsificador tuvo un buen rendimiento ,pero es ligeramente inferior al otro.\n\nPor otro lado, se puede notar que al ajustar los parámetros del clasificador (Optimización de hiperparámetros), como el tipo de kernel, ya sea linear o radial, se encontró que la configuración óptima que maximiza el rendimiento del modelo es con un kernel lineal y parametros cell_size:(8,8),block_size:(2,2),num_bins:9, al contrario la peor combinación de la configuración fue con el kernel RBF y parametros cell_size:(6,16),block_size:(3,3),num_bins:12.\n\nFinalmente, se puede decir que al combinar los descriptores LBP y HOG para la extracción de las características con el clasificador SVM, se pueden encontrar las características que son más importantes para la detección de lunares cancerígenos, De esta manera se busca comprender qué características anatomopatológicas de los lunares están correlacionadas con la malignidad. Sin embargo, es importante destacar que los resultados pueden variar según la calidad de los datos, la cantidad de datos de entrenamiento disponibles y las configuraciones de los hiperparámetros.\n\n\n","metadata":{}}]}